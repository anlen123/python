{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from snownlp import SnowNLP\n",
    "from sklearn.model_selection import  train_test_split\n",
    "import jieba as jb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>达芬奇的恶魔（一语双关）</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@战双帕弥什</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>我狂掉达尔文[微笑][微笑][微笑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[战双帕弥什_诶嘿][战双帕弥什_诶嘿][战双帕弥什_诶嘿]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>永动姬</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               PL\n",
       "0                    达芬奇的恶魔（一语双关）\n",
       "1                          @战双帕弥什\n",
       "2              我狂掉达尔文[微笑][微笑][微笑]\n",
       "3  [战双帕弥什_诶嘿][战双帕弥什_诶嘿][战双帕弥什_诶嘿]\n",
       "4                             永动姬"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('F:\\\\python\\\\代码\\\\B站在线人数\\\\情感分析\\\\pinlun_full.txt',sep='\\n')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用SnowNLP对评论进行评分\n",
    "def snow_result(comemnt):\n",
    "    S = round(SnowNLP(comemnt).sentiments,2)\n",
    "    return S\n",
    "# data = data[:100]\n",
    "data['SnowNLP']=data.PL.apply(snow_result)\n",
    "print(0)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label(df):\n",
    "    df[\"sentiment\"] = df[\"SnowNLP\"].apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('评论表.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"PL\"]]\n",
    "y = data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\jieba.cache\n",
      "Loading model cost 1.085 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "E:\\ANACONDA\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "def chinese_word_cut(mytext):\n",
    "    return \" \".join(jieba.cut(mytext))\n",
    "\n",
    "X[\"cuted_comment\"] = X.PL.apply(chinese_word_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PL</th>\n",
       "      <th>SnowNLP</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>卧槽…这么一看06年真的好棒的一年</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>那年我才八岁  还不懂什么叫神仙打架</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>以前原来一年可以有这么多好听的歌  现在的新歌榜都辣耳朵</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>99年的童年真的很丰富  电视剧动漫歌 都是巅峰</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>都是名场面！！！</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2006: .....................2019:jntm</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>全体起立</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>那些年一起听歌的人都四散在天涯</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>93年的路过 都是回忆杀</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>其实现在好的音乐还是很多的，只是因为大量的人追星爱豆，而这些爱豆就，，，然后才显得现在音乐不...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>恐怖到什么地步？恐怖到我到现在都只听老歌，新声代的歌基本都不听，更别说唱了，现在的喝唱出来我...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>原来我的童年这么幸福，一整年都不断有好听的新歌[大哭]可是现在好不容易听到不错的华语歌都觉得难得了</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>以前乐坛真是神仙打架</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>感觉周杰伦最吊的地方就是，会有很多人好奇，为啥就进了两首？然后我也想知道这个问题</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>第36首当年那么熟悉的K歌曲目，我居然今天才知道是薛之谦的……</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>真 神仙打架</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>看着突然觉得以前好的歌手百分之九九。九是港台地区的感觉那时内地不则么重视像歌手啊这样的娱乐圈...</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>。。</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>差不多全听过   只有少数几首</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>以前都觉得长辈喜欢听老歌，作为一个00后，现在自己发现，现在这些新歌真的没什么好听，还不如听...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>我十年前听的是06年的歌 十年后的现在 听的还是06年的歌 华语乐坛啊 哎</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>腾格尔：那我就不客气了！</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>QQ农场偷菜的年代</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>起立起立</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>很多歌听了就想到当时的自己，当时的心情，一部分现在还有听</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>在2019年爱上了方大同的爱爱爱</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>大多都是港台 现在感觉内地多些</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>只想说一句:mmp，劳资的青春!</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>几乎都是台湾的明星，虽然好多歌是翻唱国外的，但人家台湾还是比大陆有文化多了。</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Eason</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>15岁</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>现在的热歌确实跟以前不一样 抄的不成样了</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>在巅峰期长大的我现在都对华语新生代歌手没啥感觉了…………为什么我现在听外语？因为听不懂大概就...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>弦子人美歌甜，怎么就不火呢！</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>如果视频再配上歌词，就完美了</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>每年题目都一样[doge]</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>好希望SHE还能在一起开演唱会，没听过她们的演唱会，一辈子的遗憾[大哭]</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>tank的歌都很好听，为什么现在不见了</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>现在李荣浩的歌还是很好的</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>恋爱ing</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>你不知道现在的华语乐坛恐怖到什么地步[喜极而泣]</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   PL  SnowNLP  sentiment\n",
       "0                                   卧槽…这么一看06年真的好棒的一年     0.93          1\n",
       "1                                  那年我才八岁  还不懂什么叫神仙打架     0.94          1\n",
       "2                        以前原来一年可以有这么多好听的歌  现在的新歌榜都辣耳朵     0.52          1\n",
       "3                            99年的童年真的很丰富  电视剧动漫歌 都是巅峰     0.99          1\n",
       "4                                            都是名场面！！！     0.27          0\n",
       "5                2006: .....................2019:jntm     0.47          0\n",
       "6                                                全体起立     0.33          0\n",
       "7                                     那些年一起听歌的人都四散在天涯     0.96          1\n",
       "8                                        93年的路过 都是回忆杀     0.92          1\n",
       "9   其实现在好的音乐还是很多的，只是因为大量的人追星爱豆，而这些爱豆就，，，然后才显得现在音乐不...     0.10          0\n",
       "10  恐怖到什么地步？恐怖到我到现在都只听老歌，新声代的歌基本都不听，更别说唱了，现在的喝唱出来我...     0.13          0\n",
       "11  原来我的童年这么幸福，一整年都不断有好听的新歌[大哭]可是现在好不容易听到不错的华语歌都觉得难得了     1.00          1\n",
       "12                                         以前乐坛真是神仙打架     0.81          1\n",
       "13           感觉周杰伦最吊的地方就是，会有很多人好奇，为啥就进了两首？然后我也想知道这个问题     0.03          0\n",
       "14                    第36首当年那么熟悉的K歌曲目，我居然今天才知道是薛之谦的……     0.99          1\n",
       "15                                             真 神仙打架     0.88          1\n",
       "16  看着突然觉得以前好的歌手百分之九九。九是港台地区的感觉那时内地不则么重视像歌手啊这样的娱乐圈...     0.95          1\n",
       "17                                                 。。     0.48          0\n",
       "18                                    差不多全听过   只有少数几首     0.61          1\n",
       "19  以前都觉得长辈喜欢听老歌，作为一个00后，现在自己发现，现在这些新歌真的没什么好听，还不如听...     1.00          1\n",
       "20              我十年前听的是06年的歌 十年后的现在 听的还是06年的歌 华语乐坛啊 哎     0.75          1\n",
       "21                                       腾格尔：那我就不客气了！     0.42          0\n",
       "22                                          QQ农场偷菜的年代     0.63          1\n",
       "23                                               起立起立     0.47          0\n",
       "24                       很多歌听了就想到当时的自己，当时的心情，一部分现在还有听     0.96          1\n",
       "25                                   在2019年爱上了方大同的爱爱爱     0.86          1\n",
       "26                                    大多都是港台 现在感觉内地多些     0.95          1\n",
       "27                                   只想说一句:mmp，劳资的青春!     0.96          1\n",
       "28             几乎都是台湾的明星，虽然好多歌是翻唱国外的，但人家台湾还是比大陆有文化多了。     1.00          1\n",
       "29                                              Eason     0.50          1\n",
       "30                                                15岁     0.47          0\n",
       "31                               现在的热歌确实跟以前不一样 抄的不成样了     0.20          0\n",
       "32  在巅峰期长大的我现在都对华语新生代歌手没啥感觉了…………为什么我现在听外语？因为听不懂大概就...     1.00          1\n",
       "33                                     弦子人美歌甜，怎么就不火呢！     0.99          1\n",
       "34                                     如果视频再配上歌词，就完美了     0.96          1\n",
       "35                                      每年题目都一样[doge]     0.80          1\n",
       "36               好希望SHE还能在一起开演唱会，没听过她们的演唱会，一辈子的遗憾[大哭]     0.83          1\n",
       "37                                tank的歌都很好听，为什么现在不见了     0.35          0\n",
       "38                                       现在李荣浩的歌还是很好的     1.00          1\n",
       "39                                              恋爱ing     0.87          1\n",
       "40                           你不知道现在的华语乐坛恐怖到什么地步[喜极而泣]     0.08          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_label(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PL</th>\n",
       "      <th>cuted_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>卧槽…这么一看06年真的好棒的一年</td>\n",
       "      <td>卧槽 … 这么 一看 06 年 真的 好 棒 的 一年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>那年我才八岁  还不懂什么叫神仙打架</td>\n",
       "      <td>那年 我 才 八岁     还 不 懂 什么 叫 神仙 打架</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>以前原来一年可以有这么多好听的歌  现在的新歌榜都辣耳朵</td>\n",
       "      <td>以前 原来 一年 可以 有 这么 多好 听的歌     现在 的 新歌 榜 都 辣 耳朵</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>99年的童年真的很丰富  电视剧动漫歌 都是巅峰</td>\n",
       "      <td>99 年 的 童年 真的 很 丰富     电视剧 动漫 歌   都 是 巅峰</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>都是名场面！！！</td>\n",
       "      <td>都 是 名 场面 ！ ！ ！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2006: .....................2019:jntm</td>\n",
       "      <td>2006 :   ..................... 2019 : jntm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>全体起立</td>\n",
       "      <td>全体 起立</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>那些年一起听歌的人都四散在天涯</td>\n",
       "      <td>那些 年 一起 听歌 的 人 都 四散 在 天涯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>93年的路过 都是回忆杀</td>\n",
       "      <td>93 年 的 路过   都 是 回忆 杀</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>其实现在好的音乐还是很多的，只是因为大量的人追星爱豆，而这些爱豆就，，，然后才显得现在音乐不...</td>\n",
       "      <td>其实 现在 好 的 音乐 还是 很多 的 ， 只是 因为 大量 的 人 追星 爱豆 ， 而 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>恐怖到什么地步？恐怖到我到现在都只听老歌，新声代的歌基本都不听，更别说唱了，现在的喝唱出来我...</td>\n",
       "      <td>恐怖 到 什么 地步 ？ 恐怖 到 我 到 现在 都 只 听 老歌 ， 新声 代 的 歌 基...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>原来我的童年这么幸福，一整年都不断有好听的新歌[大哭]可是现在好不容易听到不错的华语歌都觉得难得了</td>\n",
       "      <td>原来 我 的 童年 这么 幸福 ， 一 整年 都 不断 有 好听 的 新歌 [ 大哭 ] 可...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>以前乐坛真是神仙打架</td>\n",
       "      <td>以前 乐坛 真是 神仙 打架</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>感觉周杰伦最吊的地方就是，会有很多人好奇，为啥就进了两首？然后我也想知道这个问题</td>\n",
       "      <td>感觉 周杰伦 最吊 的 地方 就是 ， 会 有 很多 人 好奇 ， 为啥 就 进 了 两首 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>第36首当年那么熟悉的K歌曲目，我居然今天才知道是薛之谦的……</td>\n",
       "      <td>第 36 首 当年 那么 熟悉 的 K 歌曲 目 ， 我 居然 今天 才 知道 是 薛之谦 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>真 神仙打架</td>\n",
       "      <td>真   神仙 打架</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>看着突然觉得以前好的歌手百分之九九。九是港台地区的感觉那时内地不则么重视像歌手啊这样的娱乐圈...</td>\n",
       "      <td>看着 突然 觉得 以前 好 的 歌手 百分之九 九 。 九是 港台地区 的 感觉 那时 内地...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>。。</td>\n",
       "      <td>。 。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>差不多全听过   只有少数几首</td>\n",
       "      <td>差不多 全听 过       只有 少数 几首</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>以前都觉得长辈喜欢听老歌，作为一个00后，现在自己发现，现在这些新歌真的没什么好听，还不如听...</td>\n",
       "      <td>以前 都 觉得 长辈 喜欢 听 老歌 ， 作为 一个 00 后 ， 现在 自己 发现 ， 现...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>我十年前听的是06年的歌 十年后的现在 听的还是06年的歌 华语乐坛啊 哎</td>\n",
       "      <td>我 十年 前 听 的 是 06 年 的 歌   十年 后 的 现在   听 的 还是 06 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>腾格尔：那我就不客气了！</td>\n",
       "      <td>腾格尔 ： 那 我 就 不 客气 了 ！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>QQ农场偷菜的年代</td>\n",
       "      <td>QQ 农场 偷菜 的 年代</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>起立起立</td>\n",
       "      <td>起立 起立</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>很多歌听了就想到当时的自己，当时的心情，一部分现在还有听</td>\n",
       "      <td>很多歌 听 了 就 想到 当时 的 自己 ， 当时 的 心情 ， 一部分 现在 还有 听</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>在2019年爱上了方大同的爱爱爱</td>\n",
       "      <td>在 2019 年 爱 上 了 方大同 的 爱爱爱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>大多都是港台 现在感觉内地多些</td>\n",
       "      <td>大多 都 是 港台   现在 感觉 内地 多些</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>只想说一句:mmp，劳资的青春!</td>\n",
       "      <td>只想 说 一句 : mmp ， 劳资 的 青春 !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>几乎都是台湾的明星，虽然好多歌是翻唱国外的，但人家台湾还是比大陆有文化多了。</td>\n",
       "      <td>几乎 都 是 台湾 的 明星 ， 虽然 好多 歌是 翻唱 国外 的 ， 但 人家 台湾 还是...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>Eason</td>\n",
       "      <td>Eason</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>15岁</td>\n",
       "      <td>15 岁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>现在的热歌确实跟以前不一样 抄的不成样了</td>\n",
       "      <td>现在 的 热歌 确实 跟 以前 不 一样   抄 的 不成 样 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>在巅峰期长大的我现在都对华语新生代歌手没啥感觉了…………为什么我现在听外语？因为听不懂大概就...</td>\n",
       "      <td>在 巅峰期 长大 的 我 现在 都 对 华语 新生代 歌手 没 啥 感觉 了 … … … …...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>弦子人美歌甜，怎么就不火呢！</td>\n",
       "      <td>弦子 人美歌 甜 ， 怎么 就 不火 呢 ！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>如果视频再配上歌词，就完美了</td>\n",
       "      <td>如果 视频 再配 上 歌词 ， 就 完美 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>每年题目都一样[doge]</td>\n",
       "      <td>每年 题目 都 一样 [ doge ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>好希望SHE还能在一起开演唱会，没听过她们的演唱会，一辈子的遗憾[大哭]</td>\n",
       "      <td>好 希望 SHE 还 能 在 一起 开 演唱会 ， 没 听 过 她们 的 演唱会 ， 一辈子...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>tank的歌都很好听，为什么现在不见了</td>\n",
       "      <td>tank 的 歌 都 很 好听 ， 为什么 现在 不见 了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>现在李荣浩的歌还是很好的</td>\n",
       "      <td>现在 李荣浩 的 歌 还是 很 好 的</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>恋爱ing</td>\n",
       "      <td>恋爱 ing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>你不知道现在的华语乐坛恐怖到什么地步[喜极而泣]</td>\n",
       "      <td>你 不 知道 现在 的 华语 乐坛 恐怖 到 什么 地步 [ 喜极而泣 ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   PL  \\\n",
       "0                                   卧槽…这么一看06年真的好棒的一年   \n",
       "1                                  那年我才八岁  还不懂什么叫神仙打架   \n",
       "2                        以前原来一年可以有这么多好听的歌  现在的新歌榜都辣耳朵   \n",
       "3                            99年的童年真的很丰富  电视剧动漫歌 都是巅峰   \n",
       "4                                            都是名场面！！！   \n",
       "5                2006: .....................2019:jntm   \n",
       "6                                                全体起立   \n",
       "7                                     那些年一起听歌的人都四散在天涯   \n",
       "8                                        93年的路过 都是回忆杀   \n",
       "9   其实现在好的音乐还是很多的，只是因为大量的人追星爱豆，而这些爱豆就，，，然后才显得现在音乐不...   \n",
       "10  恐怖到什么地步？恐怖到我到现在都只听老歌，新声代的歌基本都不听，更别说唱了，现在的喝唱出来我...   \n",
       "11  原来我的童年这么幸福，一整年都不断有好听的新歌[大哭]可是现在好不容易听到不错的华语歌都觉得难得了   \n",
       "12                                         以前乐坛真是神仙打架   \n",
       "13           感觉周杰伦最吊的地方就是，会有很多人好奇，为啥就进了两首？然后我也想知道这个问题   \n",
       "14                    第36首当年那么熟悉的K歌曲目，我居然今天才知道是薛之谦的……   \n",
       "15                                             真 神仙打架   \n",
       "16  看着突然觉得以前好的歌手百分之九九。九是港台地区的感觉那时内地不则么重视像歌手啊这样的娱乐圈...   \n",
       "17                                                 。。   \n",
       "18                                    差不多全听过   只有少数几首   \n",
       "19  以前都觉得长辈喜欢听老歌，作为一个00后，现在自己发现，现在这些新歌真的没什么好听，还不如听...   \n",
       "20              我十年前听的是06年的歌 十年后的现在 听的还是06年的歌 华语乐坛啊 哎   \n",
       "21                                       腾格尔：那我就不客气了！   \n",
       "22                                          QQ农场偷菜的年代   \n",
       "23                                               起立起立   \n",
       "24                       很多歌听了就想到当时的自己，当时的心情，一部分现在还有听   \n",
       "25                                   在2019年爱上了方大同的爱爱爱   \n",
       "26                                    大多都是港台 现在感觉内地多些   \n",
       "27                                   只想说一句:mmp，劳资的青春!   \n",
       "28             几乎都是台湾的明星，虽然好多歌是翻唱国外的，但人家台湾还是比大陆有文化多了。   \n",
       "29                                              Eason   \n",
       "30                                                15岁   \n",
       "31                               现在的热歌确实跟以前不一样 抄的不成样了   \n",
       "32  在巅峰期长大的我现在都对华语新生代歌手没啥感觉了…………为什么我现在听外语？因为听不懂大概就...   \n",
       "33                                     弦子人美歌甜，怎么就不火呢！   \n",
       "34                                     如果视频再配上歌词，就完美了   \n",
       "35                                      每年题目都一样[doge]   \n",
       "36               好希望SHE还能在一起开演唱会，没听过她们的演唱会，一辈子的遗憾[大哭]   \n",
       "37                                tank的歌都很好听，为什么现在不见了   \n",
       "38                                       现在李荣浩的歌还是很好的   \n",
       "39                                              恋爱ing   \n",
       "40                           你不知道现在的华语乐坛恐怖到什么地步[喜极而泣]   \n",
       "\n",
       "                                        cuted_comment  \n",
       "0                         卧槽 … 这么 一看 06 年 真的 好 棒 的 一年  \n",
       "1                      那年 我 才 八岁     还 不 懂 什么 叫 神仙 打架  \n",
       "2        以前 原来 一年 可以 有 这么 多好 听的歌     现在 的 新歌 榜 都 辣 耳朵  \n",
       "3             99 年 的 童年 真的 很 丰富     电视剧 动漫 歌   都 是 巅峰  \n",
       "4                                      都 是 名 场面 ！ ！ ！  \n",
       "5          2006 :   ..................... 2019 : jntm  \n",
       "6                                               全体 起立  \n",
       "7                            那些 年 一起 听歌 的 人 都 四散 在 天涯  \n",
       "8                                93 年 的 路过   都 是 回忆 杀  \n",
       "9   其实 现在 好 的 音乐 还是 很多 的 ， 只是 因为 大量 的 人 追星 爱豆 ， 而 ...  \n",
       "10  恐怖 到 什么 地步 ？ 恐怖 到 我 到 现在 都 只 听 老歌 ， 新声 代 的 歌 基...  \n",
       "11  原来 我 的 童年 这么 幸福 ， 一 整年 都 不断 有 好听 的 新歌 [ 大哭 ] 可...  \n",
       "12                                     以前 乐坛 真是 神仙 打架  \n",
       "13  感觉 周杰伦 最吊 的 地方 就是 ， 会 有 很多 人 好奇 ， 为啥 就 进 了 两首 ...  \n",
       "14  第 36 首 当年 那么 熟悉 的 K 歌曲 目 ， 我 居然 今天 才 知道 是 薛之谦 ...  \n",
       "15                                          真   神仙 打架  \n",
       "16  看着 突然 觉得 以前 好 的 歌手 百分之九 九 。 九是 港台地区 的 感觉 那时 内地...  \n",
       "17                                                。 。  \n",
       "18                            差不多 全听 过       只有 少数 几首  \n",
       "19  以前 都 觉得 长辈 喜欢 听 老歌 ， 作为 一个 00 后 ， 现在 自己 发现 ， 现...  \n",
       "20  我 十年 前 听 的 是 06 年 的 歌   十年 后 的 现在   听 的 还是 06 ...  \n",
       "21                               腾格尔 ： 那 我 就 不 客气 了 ！  \n",
       "22                                      QQ 农场 偷菜 的 年代  \n",
       "23                                              起立 起立  \n",
       "24       很多歌 听 了 就 想到 当时 的 自己 ， 当时 的 心情 ， 一部分 现在 还有 听  \n",
       "25                           在 2019 年 爱 上 了 方大同 的 爱爱爱  \n",
       "26                            大多 都 是 港台   现在 感觉 内地 多些  \n",
       "27                          只想 说 一句 : mmp ， 劳资 的 青春 !  \n",
       "28  几乎 都 是 台湾 的 明星 ， 虽然 好多 歌是 翻唱 国外 的 ， 但 人家 台湾 还是...  \n",
       "29                                              Eason  \n",
       "30                                               15 岁  \n",
       "31                  现在 的 热歌 确实 跟 以前 不 一样   抄 的 不成 样 了  \n",
       "32  在 巅峰期 长大 的 我 现在 都 对 华语 新生代 歌手 没 啥 感觉 了 … … … …...  \n",
       "33                             弦子 人美歌 甜 ， 怎么 就 不火 呢 ！  \n",
       "34                             如果 视频 再配 上 歌词 ， 就 完美 了  \n",
       "35                                每年 题目 都 一样 [ doge ]  \n",
       "36  好 希望 SHE 还 能 在 一起 开 演唱会 ， 没 听 过 她们 的 演唱会 ， 一辈子...  \n",
       "37                      tank 的 歌 都 很 好听 ， 为什么 现在 不见 了  \n",
       "38                                现在 李荣浩 的 歌 还是 很 好 的  \n",
       "39                                             恋爱 ing  \n",
       "40              你 不 知道 现在 的 华语 乐坛 恐怖 到 什么 地步 [ 喜极而泣 ]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_stopword(stop_word_file):\n",
    "    with open(stop_word_file) as f:\n",
    "        stop_word = f.read()\n",
    "        \n",
    "    stop_word_list = stop_word.split(\"/n\")\n",
    "    custom_stopword = [i for i in stop_word_list]\n",
    "    return custom_stopword\n",
    "\n",
    "stopwords = get_custom_stopword(\"F:\\\\python\\\\代码\\\\B站在线人数\\\\情感分析\\\\stop_words.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "term_matrix = DataFrame(vect.fit_transform(X_train.cuted_comment).toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 169)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['exp', 'lex', 'sub', 'sup', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｃ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', '一一', '一个', '一些', '一切', '一则', '一方面', '一旦', '一来', '一样', '一番', '一直', '一般', '万一', '上下', '不仅', '不但', '不光', '不单', '不只', '不如', '不怕', '不惟', '不成', '不拘', '不比', '不然', '不特', '不独', '不管', '不论', '不过', '不问', '与其', '与否', '与此同时', '两者', '为了', '为什么', '为何', '为着', '乃至', '之一', '之所以', '之类', '乌乎', '也好', '也就是说', '也罢', '于是', '于是乎', '云云', '人家', '什么', '什么样', '从而', '他人', '他们', '以便', '以免', '以及', '以至', '以至于', '以致', '任何', '任凭', '似的', '但是', '何况', '何处', '何时', '作为', '你们', '使得', '例如', '依照', '俺们', '倘使', '倘或', '倘然', '倘若', '假使', '假如', '假若', '关于', '其一', '其中', '其二', '其他', '其余', '其它', '其次', '具体地说', '具体说来', '再者', '再说', '况且', '几时', '凭借', '别的', '别说', '前后', '前者', '加之', '即令', '即使', '即便', '即或', '即若', '及其', '及至', '反之', '反过来', '反过来说', '另一方面', '另外', '只是', '只有', '只要', '只限', '叮咚', '可以', '可是', '可见', '各个', '各位', '各种', '各自', '同时', '向着', '否则', '吧哒', '呜呼', '呼哧', '咱们', '哈哈', '哎呀', '哎哟', '哪个', '哪些', '哪儿', '哪天', '哪年', '哪怕', '哪样', '哪边', '哪里', '哼唷', '啪达', '喔唷', '嗡嗡', '嘎登', '因为', '因此', '因而', '固然', '在下', '多少', '她们', '如上所述', '如何', '如其', '如果', '如此', '如若', '宁可', '宁愿', '宁肯', '它们', '对于', '尔后', '尚且', '就是', '就是说', '尽管', '岂但', '并且', '开外', '开始', '当着', '彼此', '怎么', '怎么办', '怎么样', '怎样', '总之', '总的来看', '总的来说', '总的说来', '总而言之', '恰恰相反', '慢说', '我们', '或是', '或者', '所以', '抑或', '按照', '换句话说', '换言之', '接着', '故此', '旁人', '无宁', '无论', '既是', '既然', '时候', '是的', '有些', '有关', '有的', '有的是', '朝着', '本着', '来着', '极了', '果然', '果真', '某个', '某些', '根据', '正如', '此外', '此间', '毋宁', '每当', '比如', '比方', '沿着', '漫说', '然则', '然后', '然而', '照着', '甚么', '甚而', '甚至', '由于', '由此可见', '的话', '相对而言', '省得', '着呢', '第二', '等等', '紧接着', '纵令', '纵使', '纵然', '经过', '结果', '继而', '综上所述', '罢了', '而且', '而况', '而外', '而已', '而是', '而言', '自个儿', '自从', '自各儿', '自家', '自己', '自身', '至于', '若是', '若非', '莫若', '虽则', '虽然', '虽说', '要不', '要不是', '要不然', '要么', '要是', '许多', '设使', '设若', '诸位', '谁知', '起见', '趁着', '越是', '较之', '还是', '还有', '这个', '这么', '这么些', '这么样', '这么点儿', '这些', '这会儿', '这儿', '这就是说', '这时', '这样', '这边', '这里', '进而', '连同', '通过', '遵照', '那个', '那么', '那么些', '那么样', '那些', '那会儿', '那儿', '那时', '那样', '那边', '那里', '鄙人', '鉴于', '除了', '除此之外', '除非', '随着', '非但', '非徒', '顺着', '首先', 'ｌｉ', 'ｎｇ昉', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "max_df = 0.8 # 在超过这一比例的文档中出现的关键词（过于平凡），去除掉。\n",
    "min_df = 3 # 在低于这一数量的文档中出现的关键词（过于独特），去除掉。\n",
    "\n",
    "vect = CountVectorizer(max_df = max_df,\n",
    "                       min_df = min_df,\n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
    "                       stop_words=frozenset(stopwords))\n",
    "\n",
    "term_matrix = DataFrame(vect.fit_transform(X_train.cuted_comment).toarray(), columns=vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 12)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=0.8,\n",
       "                                 max_features=None, min_df=3,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=frozenset({'———\\n'\n",
       "                                                       '》），\\n'\n",
       "                                                       '）÷（１－\\n'\n",
       "                                                       '”，\\n'\n",
       "                                                       '）、\\n'\n",
       "                                                       '＝（\\n'\n",
       "                                                       ':\\n'\n",
       "                                                       '→\\n'\n",
       "                                                       '℃ \\n'\n",
       "                                                       '&\\n'\n",
       "                                                       '*\\n...\n",
       "                                                       '自个儿\\n'\n",
       "                                                       '自各儿\\n'\n",
       "                                                       '自己\\n'\n",
       "                                                       '自家\\n'\n",
       "                                                       '自身\\n'\n",
       "                                                       '综上所述\\n'\n",
       "                                                       '总的来看\\n'\n",
       "                                                       '总的来说\\n'\n",
       "                                                       '总的说来\\n'\n",
       "                                                       '总而言之\\n'\n",
       "                                                       '总之\\n'\n",
       "                                                       '纵\\n'\n",
       "                                                       '纵令\\n'\n",
       "                                                       '纵然\\n'\n",
       "                                                       '纵使\\n'\n",
       "                                                       '遵照\\n'\n",
       "                                                       '作为\\n'\n",
       "                                                       '兮\\n'\n",
       "                                                       '呃\\n'\n",
       "                                                       '呗\\n'\n",
       "                                                       '咚\\n'\n",
       "                                                       '咦\\n'\n",
       "                                                       '喏\\n'\n",
       "                                                       '啐\\n'\n",
       "                                                       '喔唷\\n'\n",
       "                                                       '嗬\\n'\n",
       "                                                       '嗯\\n'\n",
       "                                                       '嗳'}),\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('multinomialnb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)\n",
    "pipe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['exp', 'lex', 'sub', 'sup', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｃ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', '一一', '一个', '一些', '一切', '一则', '一方面', '一旦', '一来', '一样', '一番', '一直', '一般', '万一', '上下', '不仅', '不但', '不光', '不单', '不只', '不如', '不怕', '不惟', '不成', '不拘', '不比', '不然', '不特', '不独', '不管', '不论', '不过', '不问', '与其', '与否', '与此同时', '两者', '为了', '为什么', '为何', '为着', '乃至', '之一', '之所以', '之类', '乌乎', '也好', '也就是说', '也罢', '于是', '于是乎', '云云', '人家', '什么', '什么样', '从而', '他人', '他们', '以便', '以免', '以及', '以至', '以至于', '以致', '任何', '任凭', '似的', '但是', '何况', '何处', '何时', '作为', '你们', '使得', '例如', '依照', '俺们', '倘使', '倘或', '倘然', '倘若', '假使', '假如', '假若', '关于', '其一', '其中', '其二', '其他', '其余', '其它', '其次', '具体地说', '具体说来', '再者', '再说', '况且', '几时', '凭借', '别的', '别说', '前后', '前者', '加之', '即令', '即使', '即便', '即或', '即若', '及其', '及至', '反之', '反过来', '反过来说', '另一方面', '另外', '只是', '只有', '只要', '只限', '叮咚', '可以', '可是', '可见', '各个', '各位', '各种', '各自', '同时', '向着', '否则', '吧哒', '呜呼', '呼哧', '咱们', '哈哈', '哎呀', '哎哟', '哪个', '哪些', '哪儿', '哪天', '哪年', '哪怕', '哪样', '哪边', '哪里', '哼唷', '啪达', '喔唷', '嗡嗡', '嘎登', '因为', '因此', '因而', '固然', '在下', '多少', '她们', '如上所述', '如何', '如其', '如果', '如此', '如若', '宁可', '宁愿', '宁肯', '它们', '对于', '尔后', '尚且', '就是', '就是说', '尽管', '岂但', '并且', '开外', '开始', '当着', '彼此', '怎么', '怎么办', '怎么样', '怎样', '总之', '总的来看', '总的来说', '总的说来', '总而言之', '恰恰相反', '慢说', '我们', '或是', '或者', '所以', '抑或', '按照', '换句话说', '换言之', '接着', '故此', '旁人', '无宁', '无论', '既是', '既然', '时候', '是的', '有些', '有关', '有的', '有的是', '朝着', '本着', '来着', '极了', '果然', '果真', '某个', '某些', '根据', '正如', '此外', '此间', '毋宁', '每当', '比如', '比方', '沿着', '漫说', '然则', '然后', '然而', '照着', '甚么', '甚而', '甚至', '由于', '由此可见', '的话', '相对而言', '省得', '着呢', '第二', '等等', '紧接着', '纵令', '纵使', '纵然', '经过', '结果', '继而', '综上所述', '罢了', '而且', '而况', '而外', '而已', '而是', '而言', '自个儿', '自从', '自各儿', '自家', '自己', '自身', '至于', '若是', '若非', '莫若', '虽则', '虽然', '虽说', '要不', '要不是', '要不然', '要么', '要是', '许多', '设使', '设若', '诸位', '谁知', '起见', '趁着', '越是', '较之', '还是', '还有', '这个', '这么', '这么些', '这么样', '这么点儿', '这些', '这会儿', '这儿', '这就是说', '这时', '这样', '这边', '这里', '进而', '连同', '通过', '遵照', '那个', '那么', '那么些', '那么样', '那些', '那会儿', '那儿', '那时', '那样', '那边', '那里', '鄙人', '鉴于', '除了', '除此之外', '除非', '随着', '非但', '非徒', '顺着', '首先', 'ｌｉ', 'ｎｇ昉', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "E:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max_df corresponds to < documents than min_df",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-030b495709a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    392\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 232\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ANACONDA\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmax_doc_count\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_doc_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m                 raise ValueError(\n\u001b[1;32m-> 1075\u001b[1;33m                     \"max_df corresponds to < documents than min_df\")\n\u001b[0m\u001b[0;32m   1076\u001b[0m             X, self.stop_words_ = self._limit_features(X, vocabulary,\n\u001b[0;32m   1077\u001b[0m                                                        \u001b[0mmax_doc_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: max_df corresponds to < documents than min_df"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X_train, y_train, cv=5, scoring='accuracy').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
